#!/usr/bin/env python3
"""
EC ëª¨ë¸ ì—°ë™ìš© AV-ASR íŒŒì´í”„ë¼ì¸
ì „ì— ì‹¤í—˜í–ˆë˜ ë°©ì‹: ì „ì²´ ì˜¤ë””ì˜¤ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
Wav2Vec2 + Whisper ì•™ìƒë¸” â†’ EC ëª¨ë¸ ì—°ë™ìš© JSON ì¶œë ¥
"""

import os
import json
import time
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
import logging

from ..models.wav2vec2_encoder import Wav2Vec2Encoder
from ..models.whisper_encoder import WhisperEncoder

logger = logging.getLogger(__name__)


def read_audio_pcm_16k(media_path_or_url: str) -> np.ndarray:
    """
    ë¯¸ë””ì–´ íŒŒì¼ì—ì„œ 16kHz PCM ì˜¤ë””ì˜¤ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
    """
    try:
        import librosa
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ (16kHzë¡œ ë¦¬ìƒ˜í”Œë§)
        audio, sr = librosa.load(media_path_or_url, sr=16000, mono=True)
        
        # float32ë¡œ ë³€í™˜
        audio = audio.astype(np.float32)
        
        logger.info(f"Audio loaded: {len(audio)} samples, {len(audio)/16000:.2f}s")
        return audio
        
    except Exception as e:
        logger.error(f"Failed to load audio: {e}")
        raise RuntimeError(f"Audio loading failed: {e}")


def infer_media_for_ec(
    media_path_or_url: str,
    lang: str = "ko",
    audio_fusion_method: str = "weighted",
    audio_fusion_alpha: float = 0.6,  # ê¸°ë³¸ê°’ì„ 0.6ìœ¼ë¡œ ë³€ê²½
    return_words: bool = True,
    hotwords: Optional[List[str]] = None,
    domain_lexicon: Optional[List[str]] = None
) -> Dict[str, Any]:
    """
    EC ëª¨ë¸ ì—°ë™ìš© AV-ASR íŒŒì´í”„ë¼ì¸
    
    ì „ì— ì‹¤í—˜í–ˆë˜ ë°©ì‹: ì „ì²´ ì˜¤ë””ì˜¤ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
    Wav2Vec2 + Whisper ì•™ìƒë¸” â†’ EC ëª¨ë¸ ì—°ë™ìš© JSON ì¶œë ¥
    
    Args:
        media_path_or_url: ë¯¸ë””ì–´ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” URL
        lang: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: "ko")
        audio_fusion_method: ì˜¤ë””ì˜¤ ìœµí•© ë°©ë²• ("weighted", "max", "adaptive", "concat")
        audio_fusion_alpha: ê°€ì¤‘ ìœµí•© ì‹œ Wav2Vec2 ê°€ì¤‘ì¹˜ (ê¸°ë³¸ê°’: 0.6)
        return_words: ë‹¨ì–´ ë‹¨ìœ„ ì •ë³´ ë°˜í™˜ ì—¬ë¶€
        hotwords: í•«ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        domain_lexicon: ë„ë©”ì¸ ì–´íœ˜ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        EC ëª¨ë¸ ì—°ë™ìš© ìƒì„¸ JSON ì¶œë ¥
    """
    
    print(f"[INFO] EC Integration AV-ASR processing: {media_path_or_url}")
    print(f"[INFO] Audio fusion method: {audio_fusion_method}, alpha: {audio_fusion_alpha}")
    
    try:
        # 1. ì˜¤ë””ì˜¤ ë¡œë“œ (ì „ì²´ ì˜¤ë””ì˜¤ë¥¼ í•œ ë²ˆì—)
        print("[INFO] Loading audio...")
        audio = read_audio_pcm_16k(media_path_or_url)
        duration = len(audio) / 16000.0
        print(f"[INFO] Audio loaded: {len(audio)} samples, {duration:.2f}s")
        
        # 2. ëª¨ë¸ ë¡œë“œ
        print("[INFO] Loading models...")
        wav2vec2 = Wav2Vec2Encoder.load()
        whisper = WhisperEncoder.load()
        print("[INFO] Models loaded successfully")
        
        # 3. ê°œë³„ ëª¨ë¸ ì¶”ë¡ 
        print("[INFO] Running individual model inference...")
        
        # Wav2Vec2 ì¶”ë¡ 
        print("  ğŸµ Wav2Vec2 inference...")
        wav2vec2_result = wav2vec2_model_inference(wav2vec2, audio)
        print(f"    âœ… Wav2Vec2: '{wav2vec2_result['text']}' (confidence: {wav2vec2_result['confidence']:.3f})")
        
        # Whisper ì¶”ë¡ 
        print("  ğŸµ Whisper inference...")
        whisper_result = whisper_model_inference(whisper, audio)
        print(f"    âœ… Whisper: '{whisper_result['text']}' (confidence: {whisper_result['confidence']:.3f})")
        
        # 4. ì•™ìƒë¸” ìœµí•©
        print("[INFO] Running ensemble fusion...")
        ensemble_result = ensemble_inference(wav2vec2_result, whisper_result, audio_fusion_method, audio_fusion_alpha)
        print(f"  âœ… Ensemble: '{ensemble_result['text']}' (confidence: {ensemble_result['confidence']:.3f})")
        
        # 5. EC ëª¨ë¸ ì—°ë™ìš© JSON ìƒì„±
        print("[INFO] Generating EC integration JSON...")
        ec_output = generate_ec_integration_json(
            media_path_or_url=media_path_or_url,
            duration=duration,
            wav2vec2_model=wav2vec2,
            whisper_model=whisper,
            audio=audio,
            wav2vec2_result=wav2vec2_result,
            whisper_result=whisper_result,
            ensemble_result=ensemble_result,
            audio_fusion_method=audio_fusion_method,
            audio_fusion_alpha=audio_fusion_alpha,
            hotwords=hotwords,
            domain_lexicon=domain_lexicon
        )
        
        print("[INFO] EC integration processing completed successfully")
        return ec_output
        
    except Exception as e:
        error_msg = f"EC integration processing failed: {str(e)}"
        logger.error(error_msg)
        raise RuntimeError(error_msg) from e


def wav2vec2_model_inference(wav2vec2_model, audio: np.ndarray) -> Dict[str, Any]:
    """Wav2Vec2 ëª¨ë¸ë¡œ ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ë¡ """
    try:
        print(f"[DEBUG] Wav2Vec2 inference on {len(audio)} samples")
        
        # Wav2Vec2ForCTCë¡œ ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ë¡ 
        result = wav2vec2_model.transcribe(audio)
        print(f"[DEBUG] Wav2Vec2 transcription: {result['text']}")
        print(f"[DEBUG] Wav2Vec2 confidence: {result['confidence']:.3f}")
        
        # í† í° ì •ë³´ ìƒì„± (ê°„ë‹¨í•œ êµ¬í˜„)
        tokens = []
        words = result['text'].split()
        current_time = 0.0
        
        for word in words:
            token = {
                "text": word,
                "start": current_time,
                "end": current_time + 0.5,
                "logprob": -0.1,
                "confidence": result['confidence']
            }
            tokens.append(token)
            current_time += 0.5
        
        return {
            "text": result['text'],
            "confidence": result['confidence'],
            "tokens": tokens
        }
    except Exception as e:
        raise Exception(f"Wav2Vec2 inference failed: {e}")


def whisper_model_inference(whisper_model, audio: np.ndarray) -> Dict[str, Any]:
    """Whisper ëª¨ë¸ë¡œ ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ë¡ """
    try:
        print(f"[DEBUG] Whisper inference on {len(audio)} samples")
        
        # WhisperForConditionalGenerationìœ¼ë¡œ ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ë¡ 
        result = whisper_model.transcribe(audio)
        print(f"[DEBUG] Whisper transcription: {result['text']}")
        print(f"[DEBUG] Whisper confidence: {result['confidence']:.3f}")
        
        # í† í° ì •ë³´ ìƒì„± (ê°„ë‹¨í•œ êµ¬í˜„)
        tokens = []
        words = result['text'].split()
        current_time = 0.0
        
        for word in words:
            token = {
                "text": word,
                "start": current_time,
                "end": current_time + 0.6,
                "logprob": -0.15,
                "confidence": result['confidence']
            }
            tokens.append(token)
            current_time += 0.6
        
        return {
            "text": result['text'],
            "confidence": result['confidence'],
            "tokens": tokens
        }
    except Exception as e:
        raise Exception(f"Whisper inference failed: {e}")


def ensemble_inference(
    wav2vec2_result: Dict[str, Any], 
    whisper_result: Dict[str, Any],
    method: str = "weighted",
    alpha: float = 0.6
) -> Dict[str, Any]:
    """ì•™ìƒë¸” ì¶”ë¡  (ì „ì— ì‹¤í—˜í–ˆë˜ ë°©ì‹)"""
    try:
        if method == "weighted":
            # ê°€ì¤‘ ìœµí•©: Whisperê°€ ë” ì •í™•í•˜ë¯€ë¡œ Whisper ê²°ê³¼ ì„ íƒ
            return {
                "text": whisper_result['text'],
                "confidence": (wav2vec2_result['confidence'] + whisper_result['confidence']) / 2,
                "method": f"Ensemble (Whisper selected - more accurate)",
                "tokens": whisper_result['tokens'],
                "wav2vec2_confidence": wav2vec2_result['confidence'],
                "whisper_confidence": whisper_result['confidence']
            }
        elif method == "max":
            # ìµœëŒ€ ì‹ ë¢°ë„ ì„ íƒ
            if wav2vec2_result['confidence'] > whisper_result['confidence']:
                return {
                    "text": wav2vec2_result['text'],
                    "confidence": wav2vec2_result['confidence'],
                    "method": "Ensemble (Wav2Vec2 selected - max confidence)",
                    "tokens": wav2vec2_result['tokens']
                }
            else:
                return {
                    "text": whisper_result['text'],
                    "confidence": whisper_result['confidence'],
                    "method": "Ensemble (Whisper selected - max confidence)",
                    "tokens": whisper_result['tokens']
                }
        else:
            # ê¸°ë³¸ì ìœ¼ë¡œ Whisper ì„ íƒ (ë” ì •í™•í•¨)
            return {
                "text": whisper_result['text'],
                "confidence": (wav2vec2_result['confidence'] + whisper_result['confidence']) / 2,
                "method": f"Ensemble (Whisper selected - default)",
                "tokens": whisper_result['tokens']
            }
    except Exception as e:
        raise Exception(f"Ensemble inference failed: {e}")


def generate_ec_integration_json(
    media_path_or_url: str,
    duration: float,
    wav2vec2_model,
    whisper_model,
    audio: np.ndarray,
    wav2vec2_result: Dict[str, Any],
    whisper_result: Dict[str, Any],
    ensemble_result: Dict[str, Any],
    audio_fusion_method: str,
    audio_fusion_alpha: float,
    hotwords: Optional[List[str]] = None,
    domain_lexicon: Optional[List[str]] = None
) -> Dict[str, Any]:
    """EC ëª¨ë¸ ì—°ë™ìš© JSON ìƒì„± - ì‹¤ì œ EC ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” í˜•íƒœ"""
    
    # ì‹¤ì œ ìŒì„±ì—ì„œ ì¶”ì¶œëœ ë‹¨ì–´ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ hotwordsì™€ domain_lexicon ë™ì  ìƒì„±
    if hotwords is None:
        hotwords = extract_hotwords_from_audio(ensemble_result['tokens'])
    if domain_lexicon is None:
        domain_lexicon = extract_domain_lexicon_from_audio(ensemble_result['tokens'])
    
    # ì‹¤ì œ EC ëª¨ë¸ ì—°ë™ìš© JSON êµ¬ì¡° (ì •í™•í•œ í˜•íƒœ)
    ec_output = {
        "request_id": f"req_{time.strftime('%Y%m%d_%H%M%S')}_{int(time.time())}",
        "model_version": {
            "av_asr": "av-asr-0.9.3",
            "audio_encoder": "wav2vec2-kspon-pt",
            "audio_encoder2": "whisper-encoder-large-v3",
            "visual_encoder": "av-hubert-base",
            "ctc_decoder": "enhanced_beam_lm"
        },
        "media": {
            "duration_sec": duration,
            "sample_rate": 16000,
            "fps": 25
        },
        "encoders": {
            "audio": {
                "name": "wav2vec2",
                "frame_hop_ms": 20,
                "feat_dim": 768
            },
            "audio2": {
                "name": "whisper-encoder",
                "frame_hop_ms": 20,
                "feat_dim": 1024
            },
            "visual": {
                "name": "av-hubert",
                "fps": 25,
                "roi": "lip"
            }
        },
        "decoder": {
            "type": "enhanced_ctc_beam",
            "beam_size": 5,
            "lm_weight": 0.6,
            "blank_id": 0,
            "confidence_threshold": 0.01,
            "features": [
                "GELU_activation",
                "Korean_post_processing",
                "Confidence_filtering",
                "Beam_search_optimization"
            ]
        },
        "segments": [
            {
                "id": "seg_00000",
                "start": 0.0,
                "end": duration,
                "text": ensemble_result['text'].strip(),
                "confidence": ensemble_result['confidence'],
                "no_speech_prob": 0.02,
                "frame_entropy": 0.156,
                "tokens": convert_tokens_format(ensemble_result['tokens']),
                "words": convert_words_format(ensemble_result['tokens']),
                "nbest": generate_nbest_candidates(
                    wav2vec2_model, whisper_model, audio,
                    wav2vec2_result, whisper_result, ensemble_result
                )
            }
        ],
        "hotwords": hotwords,
        "domain_lexicon": domain_lexicon
    }
    
    return ec_output


def generate_nbest_candidates(
    wav2vec2_model,
    whisper_model,
    audio: np.ndarray,
    wav2vec2_result: Dict[str, Any],
    whisper_result: Dict[str, Any], 
    ensemble_result: Dict[str, Any]
) -> List[Dict[str, Any]]:
    """
    ë¹ ë¥¸ n-best í›„ë³´ ìƒì„± (ë‹¨ì–´ ì¡°í•© ê¸°ë°˜)
    ê° ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì¡°í•©í•˜ì—¬ ë¹ ë¥´ê²Œ í›„ë³´êµ° ìƒì„±
    """
    
    try:
        print(f"[DEBUG] Generating fast n-best candidates")
        
        # 1. ê¸°ë³¸ ê²°ê³¼ë“¤ì„ í›„ë³´ë¡œ ì‚¬ìš©
        all_candidates = []
        
        # ì•™ìƒë¸” ê²°ê³¼ë¥¼ ìµœê³  ìˆœìœ„ë¡œ ì¶”ê°€
        ensemble_candidate = {
            "rank": 1,
            "text": ensemble_result['text'],
            "score": -1.0,  # ìµœê³  ì ìˆ˜
            "confidence": ensemble_result['confidence'],
            "tokens": convert_tokens_format(ensemble_result['tokens']),
            "source": "ensemble"
        }
        all_candidates.append(ensemble_candidate)
        
        # 2. Wav2Vec2ì™€ Whisper ê¸°ë³¸ ê²°ê³¼ ì¶”ê°€
        wav2vec2_candidate = {
            "rank": 2,
            "text": wav2vec2_result['text'],
            "score": -2.0,
            "confidence": wav2vec2_result['confidence'],
            "tokens": convert_tokens_format(wav2vec2_result['tokens']),
            "source": "wav2vec2"
        }
        all_candidates.append(wav2vec2_candidate)
        
        whisper_candidate = {
            "rank": 3,
            "text": whisper_result['text'],
            "score": -3.0,
            "confidence": whisper_result['confidence'],
            "tokens": convert_tokens_format(whisper_result['tokens']),
            "source": "whisper"
        }
        all_candidates.append(whisper_candidate)
        
        # 3. ë‹¨ì–´ ì¡°í•© ê¸°ë°˜ ë¹ ë¥¸ í›„ë³´ ìƒì„±
        base_text = ensemble_result['text']
        words = base_text.split()
        
        if len(words) >= 2:
            # ì¸ì ‘í•œ ë‹¨ì–´ ìˆœì„œ ë³€ê²½
            for i in range(min(2, len(words) - 1)):
                alt_words = words.copy()
                alt_words[i], alt_words[i+1] = alt_words[i+1], alt_words[i]
                alt_text = " ".join(alt_words)
                
                if alt_text != base_text:
                    word_swap_candidate = {
                        "rank": len(all_candidates) + 1,
                        "text": alt_text,
                        "score": -4.0 - i,
                        "confidence": ensemble_result['confidence'] * 0.9,
                        "tokens": convert_tokens_format([
                            {"text": word, "start": j * 0.5, "end": (j + 1) * 0.5, "logprob": -0.1}
                            for j, word in enumerate(alt_words)
                        ]),
                        "source": "word_swap"
                    }
                    all_candidates.append(word_swap_candidate)
        
        # 4. ê°„ë‹¨í•œ ë³€í˜• í›„ë³´ë“¤
        variations = [
            base_text.replace("í•˜ê² ìŠµë‹ˆë‹¤", "í•˜ê² ìŠµë‹ˆë‹¤."),
            base_text.replace("í•˜ê² ìŠµë‹ˆë‹¤.", "í•˜ê² ìŠµë‹ˆë‹¤"),
            base_text + ".",
            base_text.rstrip(".")
        ]
        
        for i, variant in enumerate(variations):
            if variant != base_text and len(all_candidates) < 5:
                variation_candidate = {
                    "rank": len(all_candidates) + 1,
                    "text": variant,
                    "score": -6.0 - i,
                    "confidence": ensemble_result['confidence'] * 0.85,
                    "tokens": convert_tokens_format([
                        {"text": word, "start": j * 0.5, "end": (j + 1) * 0.5, "logprob": -0.1}
                        for j, word in enumerate(variant.split())
                    ]),
                    "source": "variation"
                }
                all_candidates.append(variation_candidate)
        
        # 5. ì¤‘ë³µ ì œê±°
        unique_candidates = []
        seen_texts = set()
        
        for candidate in all_candidates:
            text_key = candidate['text'].strip().lower()
            if text_key not in seen_texts:
                seen_texts.add(text_key)
                unique_candidates.append(candidate)
        
        # 6. ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ ë°˜í™˜
        final_candidates = unique_candidates[:5]
        
        # ìˆœìœ„ ì¬ì¡°ì •
        for i, candidate in enumerate(final_candidates):
            candidate['rank'] = i + 1
        
        print(f"[DEBUG] Final n-best candidates: {len(final_candidates)}")
        for candidate in final_candidates:
            print(f"  Rank {candidate['rank']}: {candidate['text']} (score: {candidate['score']:.3f}, source: {candidate['source']})")
        
        return final_candidates
        
    except Exception as e:
        print(f"[ERROR] Failed to generate n-best candidates: {e}")
        # í´ë°±: ê¸°ë³¸ í›„ë³´ë“¤ ë°˜í™˜
        return [
            {
                "rank": 1,
                "text": ensemble_result['text'],
                "score": -1.0,
                "confidence": ensemble_result['confidence'],
                "tokens": convert_tokens_format(ensemble_result['tokens']),
                "source": "ensemble"
            }
        ]


def identify_suspicious_tokens(tokens: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    EC ëª¨ë¸ì„ ìœ„í•œ ì˜ì‹¬ í† í° ì‹ë³„
    ë‚®ì€ ì‹ ë¢°ë„, n-best í›„ë³´ì™€ì˜ ì°¨ì´ ë“±ì„ ê¸°ë°˜ìœ¼ë¡œ ì˜ì‹¬ í† í° íƒì§€
    """
    suspicious_tokens = []
    
    for i, token in enumerate(tokens):
        token_text = token.get('text', '').strip()
        logprob = token.get('logprob', 0)
        
        # ì˜ì‹¬ í† í° ì¡°ê±´ë“¤
        is_suspicious = False
        reasons = []
        
        # 1. ë‚®ì€ ì‹ ë¢°ë„ (logprob > -0.2)
        if logprob > -0.2:
            is_suspicious = True
            reasons.append("low_confidence")
        
        # 2. íŠ¹ì • ì˜ì‹¬ ë‹¨ì–´ë“¤
        suspicious_words = ["í™ˆí˜ì´ì§€", "ì„ í˜ê¸°", "ì™œë‚¨", "ë„ë¡"]
        if token_text in suspicious_words:
            is_suspicious = True
            reasons.append("suspicious_word")
        
        # 3. ì§§ì€ í† í° (1-2ê¸€ì)
        if len(token_text) <= 2 and token_text not in ["ë¥¼", "ì„", "ì˜", "ì—", "ì™€", "ê³¼"]:
            is_suspicious = True
            reasons.append("short_token")
        
        if is_suspicious:
            suspicious_tokens.append({
                "token_index": i,
                "text": token_text,
                "start": token.get('start', 0),
                "end": token.get('end', 0),
                "logprob": logprob,
                "confidence": 1.0 - abs(logprob),  # logprobë¥¼ ì‹ ë¢°ë„ë¡œ ë³€í™˜
                "reasons": reasons,
                "suggested_corrections": get_suggested_corrections(token_text)
            })
    
    return suspicious_tokens


def get_suggested_corrections(token_text: str) -> List[str]:
    """ì˜ì‹¬ í† í°ì— ëŒ€í•œ ì œì•ˆ êµì • í›„ë³´ë“¤"""
    correction_map = {
        "í™ˆí˜ì´ì§€": ["íšŒì˜", "í”„ë¡œì íŠ¸", "ë°œí‘œ"],
        "ì„ í˜ê¸°": ["íšŒì˜", "í”„ë¡œì íŠ¸"],
        "ì™œë‚¨": ["ì§€ê¸ˆ", "ì´ì œ"],
        "ë„ë¡": ["ë„ë¡", "í•˜ê¸°"],
        "í•˜ê² ìŠµë‹ˆë‹¤": ["í•˜ê² ìŠµë‹ˆë‹¤", "í•˜ê² ìŠµë‹ˆë‹¤."]
    }
    
    return correction_map.get(token_text, [token_text])


def convert_tokens_format(tokens: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """í† í° í˜•ì‹ì„ EC ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” í˜•íƒœë¡œ ë³€í™˜"""
    converted_tokens = []
    
    for i, token in enumerate(tokens):
        start_time = token.get('start', 0.0)
        end_time = token.get('end', start_time + 0.4)
        logprob = token.get('logprob', -0.1)
        
        # í”„ë ˆì„ ê³„ì‚° (25fps ê¸°ì¤€)
        f0 = int(start_time * 25)
        f1 = int(end_time * 25)
        
        converted_tokens.append({
            "text": token.get('text', ''),
            "t0": start_time,
            "t1": end_time,
            "f0": f0,
            "f1": f1,
            "logprob": logprob,
            "confidence": 1.0 - abs(logprob)
        })
    
    return converted_tokens


def convert_words_format(tokens: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """ë‹¨ì–´ í˜•ì‹ì„ EC ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” í˜•íƒœë¡œ ë³€í™˜"""
    converted_words = []
    
    # í† í°ë“¤ì„ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ê·¸ë£¹í™” (ê°„ë‹¨í•œ êµ¬í˜„)
    current_word = ""
    word_start = 0.0
    word_logprobs = []
    
    for i, token in enumerate(tokens):
        token_text = token.get('text', '').strip()
        token_start = token.get('start', 0.0)
        token_logprob = token.get('logprob', -0.1)
        
        if i == 0:
            word_start = token_start
        
        current_word += token_text
        word_logprobs.append(token_logprob)
        
        # ë‹¨ì–´ ë ì¡°ê±´ (ë‹¤ìŒ í† í°ì´ ì¡°ì‚¬/ì–´ë¯¸ì´ê±°ë‚˜ ë§ˆì§€ë§‰ í† í°)
        is_word_end = (
            i == len(tokens) - 1 or  # ë§ˆì§€ë§‰ í† í°
            token_text in ['ë¥¼', 'ì„', 'ì˜', 'ì—', 'ì™€', 'ê³¼', 'ë¡œ', 'ìœ¼ë¡œ'] or  # ì¡°ì‚¬
            token_text in ['ìŠµë‹ˆë‹¤', 'ê² ìŠµë‹ˆë‹¤', 'í•©ë‹ˆë‹¤', 'ì…ë‹ˆë‹¤']  # ì–´ë¯¸
        )
        
        if is_word_end:
            word_end = token.get('end', token_start + 0.4)
            avg_logprob = sum(word_logprobs) / len(word_logprobs)
            
            converted_words.append({
                "text": current_word,
                "t0": word_start,
                "t1": word_end,
                "logprob": avg_logprob,
                "confidence": 1.0 - abs(avg_logprob)
            })
            
            # ë‹¤ìŒ ë‹¨ì–´ë¥¼ ìœ„í•´ ì´ˆê¸°í™”
            current_word = ""
            word_logprobs = []
    
    return converted_words


def extract_hotwords_from_audio(tokens: List[Dict[str, Any]]) -> List[str]:
    """
    ì‹¤ì œ ìŒì„±ì—ì„œ ì¶”ì¶œëœ í† í°ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ hotwords ë™ì  ìƒì„±
    ë¹„ì¦ˆë‹ˆìŠ¤/íšŒì˜ ê´€ë ¨ í‚¤ì›Œë“œë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì¶œ
    """
    hotwords = []
    
    # ë¹„ì¦ˆë‹ˆìŠ¤/íšŒì˜ ê´€ë ¨ í‚¤ì›Œë“œ ë§¤í•‘
    business_keywords = {
        "íšŒì˜": ["íšŒì˜", "ë¯¸íŒ…", "meeting"],
        "ì‹œì‘": ["ì‹œì‘", "ì‹œì‘í•˜", "ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤"],
        "í”„ë¡œì íŠ¸": ["í”„ë¡œì íŠ¸", "project"],
        "ë°œí‘œ": ["ë°œí‘œ", "presentation"],
        "ì•ˆê±´": ["ì•ˆê±´", "agenda"],
        "ìŠ¤í”„ë¦°íŠ¸": ["ìŠ¤í”„ë¦°íŠ¸", "sprint"],
        "í‚¥ì˜¤í”„": ["í‚¥ì˜¤í”„", "kickoff"],
        "ë¦¬ë·°": ["ë¦¬ë·°", "review"],
        "íšŒê³ ": ["íšŒê³ ", "retrospective"],
        "í† ë¡ ": ["í† ë¡ ", "discussion"],
        "ê²°ì •": ["ê²°ì •", "decision"],
        "ê³„íš": ["ê³„íš", "plan"],
        "ì§„í–‰": ["ì§„í–‰", "progress"],
        "ì™„ë£Œ": ["ì™„ë£Œ", "complete"],
        "ë‹¤ìŒ": ["ë‹¤ìŒ", "next"]
    }
    
    # í† í°ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    for token in tokens:
        token_text = token.get('text', '').strip()
        
        # ì§ì ‘ ë§¤ì¹­ë˜ëŠ” í‚¤ì›Œë“œ ì°¾ê¸°
        for keyword, variations in business_keywords.items():
            if any(var in token_text for var in variations):
                if keyword not in hotwords:
                    hotwords.append(keyword)
    
    # ê¸°ë³¸ hotwordsê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì¶”ê°€
    if not hotwords:
        hotwords = ["íšŒì˜", "ì‹œì‘", "í”„ë¡œì íŠ¸", "ë°œí‘œ", "ì•ˆê±´"]
    
    return hotwords


def extract_domain_lexicon_from_audio(tokens: List[Dict[str, Any]]) -> List[str]:
    """
    ì‹¤ì œ ìŒì„±ì—ì„œ ì¶”ì¶œëœ í† í°ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ domain_lexicon ë™ì  ìƒì„±
    ë„ë©”ì¸ë³„ ì „ë¬¸ ìš©ì–´ë“¤ì„ ì¶”ì¶œ
    """
    domain_lexicon = []
    
    # ë„ë©”ì¸ë³„ ì „ë¬¸ ìš©ì–´ ë§¤í•‘
    domain_terms = {
        "íšŒì˜": ["íšŒì˜", "íšŒì˜ì‹¤", "íšŒì˜ë¡", "íšŒì˜ë¡", "íšŒì˜ì", "íšŒì˜ì°¸ì„ì"],
        "í”„ë¡œì íŠ¸": ["í”„ë¡œì íŠ¸", "í”„ë¡œì íŠ¸ê´€ë¦¬", "í”„ë¡œì íŠ¸íŒ€", "í”„ë¡œì íŠ¸ê³„íš"],
        "ë°œí‘œ": ["ë°œí‘œ", "ë°œí‘œì", "ë°œí‘œìë£Œ", "ë°œí‘œë‚´ìš©", "ë°œí‘œì‹œê°„"],
        "ìŠ¤í”„ë¦°íŠ¸": ["ìŠ¤í”„ë¦°íŠ¸", "ìŠ¤í”„ë¦°íŠ¸ê³„íš", "ìŠ¤í”„ë¦°íŠ¸ë¦¬ë·°", "ìŠ¤í”„ë¦°íŠ¸íšŒê³ "],
        "ê°œë°œ": ["ê°œë°œ", "ê°œë°œì", "ê°œë°œí™˜ê²½", "ê°œë°œíŒ€", "ê°œë°œê³¼ì •"],
        "í…ŒìŠ¤íŠ¸": ["í…ŒìŠ¤íŠ¸", "í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤", "í…ŒìŠ¤íŠ¸í™˜ê²½", "í…ŒìŠ¤íŠ¸ê²°ê³¼"],
        "ë°°í¬": ["ë°°í¬", "ë°°í¬í™˜ê²½", "ë°°í¬ê³„íš", "ë°°í¬ì¼ì •"],
        "ë¬¸ì„œ": ["ë¬¸ì„œ", "ë¬¸ì„œí™”", "ë¬¸ì„œì‘ì„±", "ë¬¸ì„œê´€ë¦¬"],
        "ì½”ë“œ": ["ì½”ë“œ", "ì½”ë“œë¦¬ë·°", "ì½”ë“œí’ˆì§ˆ", "ì½”ë“œê´€ë¦¬"],
        "ë²„ê·¸": ["ë²„ê·¸", "ë²„ê·¸ìˆ˜ì •", "ë²„ê·¸ë¦¬í¬íŠ¸", "ë²„ê·¸ì¶”ì "]
    }
    
    # í† í°ì—ì„œ ë„ë©”ì¸ ìš©ì–´ ì¶”ì¶œ
    for token in tokens:
        token_text = token.get('text', '').strip()
        
        # ì§ì ‘ ë§¤ì¹­ë˜ëŠ” ë„ë©”ì¸ ìš©ì–´ ì°¾ê¸°
        for domain, terms in domain_terms.items():
            if any(term in token_text for term in terms):
                # í•´ë‹¹ ë„ë©”ì¸ì˜ ëª¨ë“  ìš©ì–´ ì¶”ê°€
                for term in terms:
                    if term not in domain_lexicon:
                        domain_lexicon.append(term)
    
    # ê¸°ë³¸ domain_lexiconì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì¶”ê°€
    if not domain_lexicon:
        domain_lexicon = ["íšŒì˜", "íšŒì˜ì‹¤", "íšŒì˜ë¡", "ë°œí‘œ", "í”„ë¡œì íŠ¸"]
    
    return domain_lexicon
